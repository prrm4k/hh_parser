{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfw2eh6z5-Hn"
      },
      "source": [
        "Город\n",
        "\n",
        "Зарплата\n",
        "\n",
        "Компания\n",
        "\n",
        "Опыт\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16 - Беларусь\n",
        "\n",
        "28 - Грузия\n",
        "\n",
        "40 - Казахстан\n",
        "\n",
        "48 - Кыргызстан\n",
        "\n",
        "97 - Узбекистан\n",
        "\n",
        "113 - Россия\n"
      ],
      "metadata": {
        "id": "zUzUutWRk2xE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "client_ID = ''\n",
        "client_secret = ''\n",
        "token_url = 'https://hh.ru/oauth/token'\n",
        "data={'grant_type': 'client_credentials',\n",
        "      'client_id': client_ID,\n",
        "      'client_secret': client_secret}\n",
        "\n",
        "response = requests.post(token_url, data=data)\n",
        "access_token = response.json()['access_token']"
      ],
      "metadata": {
        "id": "fKz-IQ_iPvLn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz6v83dTTVti",
        "outputId": "3e603ad8-ed45-444a-8dac-b89a7a88ab1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fake_useragent\n",
            "  Downloading fake_useragent-1.4.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: fake_useragent\n",
            "Successfully installed fake_useragent-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install fake_useragent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di6xxRHZABv-",
        "outputId": "7ef590ce-4b00-4edd-f46b-32c9f2200d15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os\n",
        "from fake_useragent import UserAgent\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l11luIQ2cBb6"
      },
      "source": [
        "# Резюме"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QFjP7C6jFpIK"
      },
      "outputs": [],
      "source": [
        "def parse_age(age: list):\n",
        "  if len(age) == 4:\n",
        "    age_num = round(int(age[0]) + int(age[2]) / 12, 1)\n",
        "  else:\n",
        "    if ('год' in age[1]) | ('лет' in age[1]):\n",
        "      age_num = int(age[0])\n",
        "    else:\n",
        "      age_num = round(int(age[0]) / 12, 1)\n",
        "  return age_num"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_ress = 'архитектор гап пгс отопление-вентиляция Водоснабжение-Канализация Электроснабжение эколог BIM'.split()\n",
        "new_list=[]\n",
        "for i in list_of_ress:\n",
        "  url = f'https://rabota.by/search/resume?text={i}&logic=normal&pos=position&exp_period=all_time&exp_company_size=any&filter_exp_period=all_time&area=97&relocation=living&age_from=&age_to=&gender=unknown&salary_from=&salary_to=&currency_code=BYR&order_by=relevance&search_period=30&items_on_page=20&no_magic=true&'\n",
        "  response = requests.get(url, headers={\n",
        "        'User-Agent': UserAgent().chrome\n",
        "      })\n",
        "  content = response.content\n",
        "  parsed_content = BeautifulSoup(content, 'html.parser')\n",
        "  try:\n",
        "    page_count = int(parsed_content.find_all(\"span\",{\"class\":\"pager-item-not-in-short-range\"})[-1].find('span').get_text())\n",
        "    for pg in range(1, page_count+1):\n",
        "      url = f'https://rabota.by/search/resume?text={i}&logic=normal&pos=position&exp_period=all_time&exp_company_size=any&filter_exp_period=all_time&area=97&relocation=living&age_from=&age_to=&gender=unknown&salary_from=&salary_to=&currency_code=BYR&order_by=relevance&search_period=30&items_on_page=20&no_magic=true&page={pg}'\n",
        "      response = requests.get(url, headers={\n",
        "        'User-Agent': UserAgent().chrome\n",
        "      })\n",
        "      content = response.content\n",
        "      parsed_content = BeautifulSoup(content, 'html.parser')\n",
        "      for link in parsed_content.select('a[class=serp-item__title]'):\n",
        "        href = link.get('href')\n",
        "        new_list.append('https://rabota.by' + href)\n",
        "  except:\n",
        "      url = f'https://rabota.by/search/resume?text={i}&logic=normal&pos=position&exp_period=all_time&exp_company_size=any&filter_exp_period=all_time&area=97&relocation=living&age_from=&age_to=&gender=unknown&salary_from=&salary_to=&currency_code=BYR&order_by=relevance&search_period=30&items_on_page=20&no_magic=true&page'\n",
        "      response = requests.get(url, headers={\n",
        "        'User-Agent': UserAgent().chrome\n",
        "      })\n",
        "      content = response.content\n",
        "      parsed_content = BeautifulSoup(content, 'html.parser')\n",
        "      for link in parsed_content.select('a[class=serp-item__title]'):\n",
        "        href = link.get('href')\n",
        "        new_list.append('https://rabota.by' + href)\n"
      ],
      "metadata": {
        "id": "YO1fDWrXTah1"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "LvyCnfthxLlg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4474824e-5189-4e4e-c355-810b83a8095f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "len(new_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "MMMYJBVjcGop"
      },
      "outputs": [],
      "source": [
        "gender = []\n",
        "age = []\n",
        "status = []\n",
        "city = []\n",
        "position = []\n",
        "salary = []\n",
        "type_of_emp = []\n",
        "last_work = []\n",
        "educ = []\n",
        "curr = []\n",
        "total_exp = []\n",
        "lw_exp = []\n",
        "for url in new_list:\n",
        "  response = requests.get(url, headers={\n",
        "        'User-Agent': UserAgent().chrome\n",
        "      })\n",
        "  content = response.content\n",
        "  parsed_content = BeautifulSoup(content, 'html.parser')\n",
        "  # try:\n",
        "  gender.append(str(parsed_content.find('span', {'data-qa': 'resume-personal-gender'}))[39:-7])\n",
        "  # except:\n",
        "  #   gender.append('unk')\n",
        "  try:\n",
        "    age.append(str(parsed_content.find('span', {'data-qa': 'resume-personal-age'}))[42:44])\n",
        "  except:\n",
        "    age.append('unk')\n",
        "  try:\n",
        "    status.append(str(parsed_content.find('div', {'class': 'resume-job-search-status'}))[206:-71])\n",
        "  except:\n",
        "    status.append('unk')\n",
        "  # try:\n",
        "  city.append(str(parsed_content.find('span', {'data-qa': 'resume-personal-address'}))[40:-7])\n",
        "  # except:\n",
        "    # city.append('unk')\n",
        "  position.append(str(parsed_content.find('span', {'data-qa': 'resume-block-title-position'}))[77:-7])\n",
        "  try:\n",
        "    type_of_emp.append(parsed_content.find('div', {'class': 'resume-block-container'}).find('p').get_text()[11:])\n",
        "  except:\n",
        "    type_of_emp.append('unk')\n",
        "  try:\n",
        "    last_work.append(parsed_content.find('div', {'class': 'bloko-text bloko-text_strong'}).get_text())\n",
        "  except:\n",
        "    last_work.append('unk')\n",
        "  try:\n",
        "    educ.append(parsed_content.find('div', {'data-qa': 'resume-block-education-name'}).find('a').get_text())\n",
        "  except:\n",
        "    try:\n",
        "      educ.append(parsed_content.find('div', {'data-qa': 'resume-block-education-name'}).get_text())\n",
        "    except:\n",
        "      educ.append('unk')\n",
        "  try:\n",
        "    salary.append(parsed_content.find('span', {'class': 'resume-block__salary'}).get_text().replace('\\u2009', '').replace('\\xa0' , ' ').split()[0])\n",
        "  except:\n",
        "    salary.append(0)\n",
        "  try:\n",
        "    curr.append((parsed_content.find('span', {'class': 'resume-block__salary'}).get_text().replace('\\u2009', '').replace('\\xa0' , ' ').split()[1]))\n",
        "  except:\n",
        "    curr.append(0)\n",
        "  try:\n",
        "    total_exp.append(parse_age(parsed_content.find('span', {'class': 'resume-block__title-text resume-block__title-text_sub'}).get_text().replace('\\xa0', ' ')[12:].split()))\n",
        "  except:\n",
        "    total_exp.append('unk')\n",
        "  try:\n",
        "    lw_exp.append(parse_age(parsed_content.find('div', {'class': 'bloko-text bloko-text_tertiary'}).find('span').get_text().replace('\\xa0' , ' ').split()))\n",
        "  except:\n",
        "    lw_exp.append('unl')\n",
        "df = pd.DataFrame({'url': new_list,'position': position, 'salary': salary, 'total_exp': total_exp, 'currency': curr, 'status': status, 'gender':gender, 'age':age, 'city':city, 'type_of_emp':type_of_emp, 'last_work': last_work,'lw_exp': lw_exp, 'educ': educ})\n",
        "df.type_of_emp = df.type_of_emp.map(lambda x:x.split(', ')[0]).replace({'unk': 'полная занятость'})\n",
        "df['date'] = str(datetime.date.today())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "dWApXJA4NYyS"
      },
      "outputs": [],
      "source": [
        "def convert_res(df):\n",
        "  df.currency = df.currency.replace({'Br': \"BYR\", '₽': 'RUB', '$': 'USD', '₸' : 'KZT', 0:'BYR', \"so'm\": 'UZS', '€': 'EUR'})\n",
        "  df.salary = df.salary.astype('int')\n",
        "  unique_curs = [i for i in df.currency.unique() if isinstance(i, str) & (i !='BYR')]\n",
        "  for curr in unique_curs:\n",
        "    course, scale = requests.get(f'https://api.nbrb.by/exrates/rates/{curr}?parammode=2').json()['Cur_OfficialRate'], requests.get(f'https://api.nbrb.by/exrates/rates/{curr}?parammode=2').json()['Cur_Scale']\n",
        "    df.salary[df.currency==curr] = df.salary[df.currency==curr] * course / scale\n",
        "  df.currency= 'BYR'\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2l0y-xQNJsT",
        "outputId": "7e483eda-37b8-4fd1-e2e2-9a87739204d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-98-6de666c2a260>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.salary[df.currency==curr] = df.salary[df.currency==curr] * course / scale\n"
          ]
        }
      ],
      "source": [
        "df = convert_res(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "rPnfpgONQSMC"
      },
      "outputs": [],
      "source": [
        "def to_google_res(df:pd.DataFrame, path = ''):\n",
        "  os.chdir(f'/content/gdrive/My Drive/{path}')\n",
        "  df.to_csv('resumes.xlsx')\n",
        "  return print('succes!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJJa7koEQ5x0",
        "outputId": "0406f59a-e62b-446b-8c9d-23b878b89c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "succes!\n"
          ]
        }
      ],
      "source": [
        "to_google_res(df, 'vacancies_kz')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvKmWv_mReKK"
      },
      "source": [
        "# Вакансии"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8ySVqQw6rnu"
      },
      "outputs": [],
      "source": [
        "def collects_vacancies_hh(job_title: str, area=16):\n",
        "  number_of_pages = 100\n",
        "#number_of_ads = number_of_pages * per_page\n",
        "  job_title = job_title.split()\n",
        "  for job in job_title:\n",
        "      data=[]\n",
        "      for i in tqdm(range(number_of_pages)):\n",
        "         url = 'https://api.hh.ru/vacancies'\n",
        "         par = {'text': job, 'area':str(area),'per_page':'10', 'page':i, 'search_period':'30'}\n",
        "         r = requests.get(url, params=par)\n",
        "         e=r.json()\n",
        "         data.append(e)\n",
        "         vacancy_details = data[0]['items'][0].keys()\n",
        "         df = pd.DataFrame(columns= list(vacancy_details))\n",
        "         ind = 0\n",
        "         for i in range(len(data)):\n",
        "             for j in range(len(data[i]['items'])):\n",
        "                 df.loc[ind] = data[i]['items'][j]\n",
        "                 ind+=1\n",
        "         csv_name = job+\".csv\"\n",
        "         df.to_csv(csv_name)\n",
        "  return print('/nCollection of vacancies was finished!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YasJrMz1p3A_"
      },
      "outputs": [],
      "source": [
        "def preprocessing(dataframe: pd.DataFrame, position: str):\n",
        "  position = position.split()\n",
        "  dataframe = dataframe[dataframe.name.str.lower().str.contains(position[0].lower(), regex=False)]\n",
        "  if len(position) > 1:\n",
        "    for i in [1, len(position) - 1]:\n",
        "      dataframe = pd.concat([dataframe,  dataframe[dataframe.name.str.lower().str.contains(position[i].lower(), regex=False)]], axis=0)\n",
        "  dataframe = dataframe[['name', 'area', 'salary', 'address', 'employer', 'schedule',  'experience', 'employment', 'alternate_url']].reset_index().drop(columns=['index'])\n",
        "  df_help = dataframe[['salary', 'address']]\n",
        "  for col in ['area', 'employer', 'schedule',  'experience', 'employment']:\n",
        "    dataframe[col] = dataframe[col].apply(lambda x: eval(x.replace(\"'\", '\"'))).map(lambda x: x['name'])\n",
        "  df_help.fillna(0, inplace=True)\n",
        "  df_help['from_s'] = df_help['salary'].apply(lambda x: eval(x.replace(\"'\", '\"'))['from'] if x!=0 else 0)\n",
        "  df_help['to_s'] = df_help['salary'].apply(lambda x: eval(x.replace(\"'\", '\"'))['to'] if x!=0 else 0)\n",
        "  df_help['cur_s'] = df_help['salary'].apply(lambda x: eval(x.replace(\"'\", '\"'))['currency'] if x!=0 else 0)\n",
        "  dataframe_final = pd.concat([dataframe, df_help[['from_s', 'to_s',\t'cur_s']]], axis=1).fillna(0)\n",
        "  dataframe_final = dataframe_final[dataframe_final.employer != 'ЭНЭКА'].reset_index().drop(columns=['index', 'salary', 'address'])\n",
        "  dataframe_final['date'] = str(datetime.date.today())\n",
        "  return dataframe_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3MxTIdOfpti"
      },
      "outputs": [],
      "source": [
        "def convert(dataframe: pd.DataFrame):\n",
        "  dataframe.cur_s = dataframe.cur_s.replace('RUR', 'RUB')\n",
        "  unique_curs = [i for i in dataframe.cur_s.unique() if isinstance(i, str) & (i !='BYR')]\n",
        "  for curs in unique_curs:\n",
        "      course, scale = requests.get(f'https://api.nbrb.by/exrates/rates/{curs}?parammode=2').json()['Cur_OfficialRate'], requests.get(f'https://api.nbrb.by/exrates/rates/{curs}?parammode=2').json()['Cur_Scale']\n",
        "      dataframe.to_s[dataframe.cur_s==curs] = dataframe.to_s[dataframe.cur_s==curs] * course / scale\n",
        "      dataframe.from_s[dataframe.cur_s==curs] = dataframe.from_s[dataframe.cur_s==curs] * course / scale\n",
        "      dataframe.cur_s[dataframe.cur_s==curs] = 'BYR'\n",
        "  dataframe.from_s=dataframe.from_s.astype('float32')\n",
        "  dataframe.to_s=dataframe.to_s.astype('float32')\n",
        "  return dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GELF5b-nxQA"
      },
      "outputs": [],
      "source": [
        "def convert_to_excel(list_of_dfs: str, excel_name: str):\n",
        "  list_of_dfs = list_of_dfs.split()\n",
        "  writer = pd.ExcelWriter(f'{excel_name}.xlsx')\n",
        "  agg = pd.DataFrame()\n",
        "  for i in list_of_dfs:\n",
        "    time = eval(i)\n",
        "    time.to_excel(writer, sheet_name=i)\n",
        "    agg = pd.concat([agg, time], axis=0)\n",
        "  agg.to_excel(writer, sheet_name='agg')\n",
        "  writer.save()\n",
        "  return print('Saving was finished succesfully!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "lkDxZ3VRqP9K",
        "outputId": "3574434c-6255-4d8b-a581-2a66c89fbf7c"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-e9e28eced9aa>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def to_google_update(list_of_dfs: str):\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ],
      "source": [
        "def to_google_update(list_of_dfs: str):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUAQzTygkLj8"
      },
      "outputs": [],
      "source": [
        "def to_google_new(list_of_dfs: str):\n",
        "  list_of_dfs = list_of_dfs.split()\n",
        "  # os.mkdir('/content/gdrive/My Drive/vacancies_rf')\n",
        "  os.chdir('/content/gdrive/My Drive/vacancies_rf')\n",
        "  agg = pd.DataFrame()\n",
        "  for i in list_of_dfs:\n",
        "    time = eval(i)\n",
        "    time.to_excel(f'{i}.xlsx')\n",
        "    agg = pd.concat([agg, time], axis=0)\n",
        "  agg.alternate_url.drop_duplicates(inplace=True)\n",
        "  agg.to_csv('agg.xlsx')\n",
        "  return print('succes!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGUNquMHCOnT"
      },
      "outputs": [],
      "source": [
        "'архитектор пгс отопление-вентиляция Водоснабжение-Канализация Электроснабжение'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUZhxfFf0K1x"
      },
      "outputs": [],
      "source": [
        "collects_vacancies_hh('эколог BIM', area=113)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muiOmH6i5LLr"
      },
      "outputs": [],
      "source": [
        "arhitektor = convert(preprocessing(pd.read_csv('/content/архитектор.csv'), 'архитектор architect'))\n",
        "pgs = convert(preprocessing(pd.read_csv('/content/пгс.csv'), 'конструктор пгс'))\n",
        "ov = convert(preprocessing(pd.read_csv('/content/отопление-вентиляция.csv'), 'отопление проектировщик вентиляция ОВ ок овик'))\n",
        "vk = convert(preprocessing(pd.read_csv('/content/Водоснабжение-Канализация.csv'), 'проектировщик водоснабжение канализация ОВ ок овик'))\n",
        "es = convert(preprocessing(pd.read_csv('/content/Электроснабжение.csv'), 'проектировщик электроснабжение э'))\n",
        "ie = convert(preprocessing(pd.read_csv('/content/эколог.csv'), 'эколог'))\n",
        "bim = convert(preprocessing(pd.read_csv('/content/BIM.csv'), 'bim'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIbqlqci6mlR",
        "outputId": "4359368f-b00d-4097-9b60-cee347b7c456"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "succes!\n"
          ]
        }
      ],
      "source": [
        "to_google_new('arhitektor pgs ov vk es ie bim')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "YvKmWv_mReKK",
        "qed65FMcykVq"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}